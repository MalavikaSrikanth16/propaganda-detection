{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Causal_oversimplification_feature_based_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtonyutgKtO_",
        "colab_type": "code",
        "outputId": "fa0bbff0-a159-408d-d2df-808727aa3ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi0fy7OcK0Pu",
        "colab_type": "code",
        "outputId": "c8c48d53-170f-4a2a-cb56-40d473ea4033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASzlkONVK2Xu",
        "colab_type": "code",
        "outputId": "68896a19-0bf7-440d-8801-c5695559aa35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "import random\n",
        "import numpy as np\n",
        "import glob\n",
        "import os.path\n",
        "import codecs\n",
        "import pandas as pd\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn as nn\n",
        "\n",
        "seed_val = 16\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "root_path = \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZUS4KL_K4do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = root_path + \"causal_datasets_with_features/\"\n",
        "train_csv = dataset_path + \"unbalanced_train_dataset_80_20.csv\"\n",
        "dev_csv = dataset_path + \"unbalanced_dev_dataset_80_20.csv\"\n",
        "test_csv = dataset_path + \"climate_change_with_predictions.csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_csv)\n",
        "df_dev = pd.read_csv(dev_csv)\n",
        "df_test = pd.read_csv(test_csv)\n",
        "\n",
        "\n",
        "def get_features(df):\n",
        "  framenet_causal = df['Framenet causal score'].values\n",
        "  causal_links_presence = df['Causal link presence'].values\n",
        "  #causal_verbs_presence= df['Causal verb presence'].values\n",
        "  pretrained_classifier_score = df['Pre-trained causal classifier labels'].values\n",
        "  return framenet_causal, causal_links_presence, pretrained_classifier_score\n",
        "\n",
        "train_framenet_causal, train_causal_links, train_pretrained_label = get_features(df_train)\n",
        "dev_framenet_causal, dev_causal_links, dev_pretrained_label = get_features(df_dev)\n",
        "test_framenet_causal, test_causal_links, test_pretrained_label = get_features(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YJIH_hH6adq",
        "colab_type": "code",
        "outputId": "682340fe-2a21-4a4a-83d5-68d5e957e81c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_labels = df_train['Labels'].values\n",
        "dev_labels = df_dev['Labels'].values\n",
        "\n",
        "print(train_labels.shape)\n",
        "print(dev_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5061,)\n",
            "(1072,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCKF7ES_eVEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.column_stack((train_framenet_causal, train_pretrained_label, train_causal_links))\n",
        "x_dev = np.column_stack((dev_framenet_causal, dev_pretrained_label, dev_causal_links))\n",
        "x_test = np.column_stack((test_framenet_causal, test_pretrained_label, test_causal_links))\n",
        "\n",
        "#x_train = train_pretrained_label.reshape(-1,1)\n",
        "#x_dev = dev_pretrained_label.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au5GK61neskn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg_model = LogisticRegression(random_state=0,class_weight='balanced')\n",
        "logreg_model.fit(x_train, train_labels)\n",
        "predicted_labels = logreg_model.predict(x_dev)\n",
        "\n",
        "test_predicted_labels = logreg_model.predict(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbBNg74apFH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_dev['Log reg classifier predictions'] = predicted_labels\n",
        "# df_dev.to_csv(root_path + \"causal_datasets_with_features/dev_80_20_with_predictions.csv\")\n",
        "df_test['Log reg predictions'] = test_predicted_labels\n",
        "df_test.to_csv(test_csv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Fzqek5fbbp",
        "colab_type": "code",
        "outputId": "15ab82e8-de27-4fd0-a451-2519511564cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy of classifier - \", accuracy_score(dev_labels, predicted_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of classifier -  0.6940298507462687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvjub8aBfcQ4",
        "colab_type": "code",
        "outputId": "37c7d5ff-caf7-4e95-8b1b-979bfafd3588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(\"Confusion matrix values - \")\n",
        "tn, fp, fn, tp = confusion_matrix(dev_labels, predicted_labels).ravel()\n",
        "print(\"TP - \", tp)\n",
        "print(\"FN - \", fn)\n",
        "print(\"TN - \", tn)\n",
        "print(\"FP - \", fp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix values - \n",
            "TP -  23\n",
            "FN -  19\n",
            "TN -  721\n",
            "FP -  309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuIaN5cPfcVH",
        "colab_type": "code",
        "outputId": "bec9aabf-7a6d-4ddf-8083-b5c1d3a4bdfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"F1-score of classifier on each class - \", f1_score(dev_labels, predicted_labels, average=None))\n",
        "print(\"Macro averaged F1-score of classifier - \", f1_score(dev_labels, predicted_labels, average='macro'))\n",
        "print(\"Weighted averaged F1-score of classifier - \", f1_score(dev_labels, predicted_labels, average='weighted'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score of classifier on each class -  [0.81468927 0.12299465]\n",
            "Macro averaged F1-score of classifier -  0.46884195897157016\n",
            "Weighted averaged F1-score of classifier -  0.7875892900222895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu1WeHjjfh6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}